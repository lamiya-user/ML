# -*- coding: utf-8 -*-
"""Predicting housing prices using rd.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AG76t5wNr9bi6lZ5fC_CJT6Wqm5G0jsK
"""

!pip install numpy
!pip install scikit-learn
!pip install matplotlib
!pip install xgboost

import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
from sklearn.metrics import mean_squared_error, r2_score
import time

"""load the data"""

data = fetch_california_housing()
x,y = data.data,data.target
x_train,x_test,y_train,y_test =train_test_split(x,y,test_size=0.2,random_state=42)

"""to show the number of observations"""

n_observations, n_features =x.shape
print("no. of obs="+str(n_observations))
print("no.of feat="+str(n_features))

"""initialise"""

n_estimators =100
rf = RandomForestRegressor(n_estimators =n_estimators, random_state=42)
xgb = XGBRegressor(n_estimators=n_estimators, random_state=42)

"""fit models
measure training time for rf
measure training time for xgboost
"""

start_time_rf =time.time()
rf.fit(x_train, y_train)
end_time_rf =time.time()
rf_train_time = end_time_rf -start_time_rf

start_time_xgb =time.time()
xgb.fit(x_train, y_train)
end_time_xgb =time.time()
xgb_train_time = end_time_xgb -start_time_xgb

# Enter your code here

# Measure prediction time for Random Forest
start_time_rf = time.time()
y_pred_rf = rf.predict(x_test)
end_time_rf = time.time()
rf_pred_time = end_time_rf -start_time_rf

# Measure prediction time for XGBoost
start_time_xgb = time.time()
y_pred_xgb = rf.predict(x_test)
end_time_xgb = time.time()
xgb_pred_time = end_time_rf -start_time_rf

# Enter your code here

mse_rf = mean_squared_error(y_test, y_pred_rf)
mse_xgb = mean_squared_error(y_test, y_pred_xgb)
r2_rf = r2_score(y_test , y_pred_rf)
r2_xgb = r2_score(y_test, y_pred_xgb)

# Enter your code here

print(f'Random Forest:  MSE = {mse_rf:.4f}, R^2 = {r2_rf:.4f}')
print(f'      XGBoost:  MSE = {mse_xgb:.4f},R^2 = {r2_xgb:.4f}.')

print(f'Random Forest:  Training Time = {rf_train_time:.3f} seconds, Testing time = {rf_pred_time:.3f} seconds')
print(f'      XGBoost:  Training Time = {xgb_train_time:.3f} seconds, Testing time = {xgb_pred_time:.3f} seconds')

std_y = np.std(y_test)

start_time_rf = time.time()
y_pred_rf = rf.predict(x_test)
end_time_rf = time.time()
rf_pred_time = end_time_rf - start_time_rf

# Measure prediciton time for XGBoost
start_time_xgb = time.time()
y_pred_xgb = xgb.predict(x_test)
end_time_xgb = time.time()
xgb_pred_time = end_time_xgb - start_time_xgb

mse_rf = mean_squared_error(y_test, y_pred_rf)
mse_xgb = mean_squared_error(y_test, y_pred_xgb)
r2_rf = r2_score(y_test, y_pred_rf)
r2_xgb = r2_score(y_test, y_pred_xgb)

print(f'Random Forest:  MSE = {mse_rf:.4f}, R^2 = {r2_rf:.4f}')
print(f'      XGBoost:  MSE = {mse_xgb:.4f}, R^2 = {r2_xgb:.4f}')
print(f'Random Forest:  Training Time = {rf_train_time:.3f} seconds, Testing time = {rf_pred_time:.3f} seconds')
print(f'      XGBoost:  Training Time = {xgb_train_time:.3f} seconds, Testing time = {xgb_pred_time:.3f} seconds')
std_y = np.std(y_test)

plt.figure(figsize=(14, 6))

# Random Forest plot
plt.subplot(1, 2, 1)
plt.scatter(y_test, y_pred_rf, alpha=0.5, color="blue",ec='k')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2,label="perfect model")
plt.plot([y_test.min(), y_test.max()], [y_test.min() + std_y, y_test.max() + std_y], 'r--', lw=1, label="+/-1 Std Dev")
plt.plot([y_test.min(), y_test.max()], [y_test.min() - std_y, y_test.max() - std_y], 'r--', lw=1, )
plt.ylim(0,6)
plt.title("Random Forest Predictions vs Actual")
plt.xlabel("Actual Values")
plt.ylabel("Predicted Values")
plt.legend()


# XGBoost plot
plt.subplot(1, 2, 2)
plt.scatter(y_test, y_pred_xgb, alpha=0.5, color="orange",ec='k')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2,label="perfect model")
plt.plot([y_test.min(), y_test.max()], [y_test.min() + std_y, y_test.max() + std_y], 'r--', lw=1, label="+/-1 Std Dev")
plt.plot([y_test.min(), y_test.max()], [y_test.min() - std_y, y_test.max() - std_y], 'r--', lw=1, )
plt.ylim(0,6)
plt.title("XGBoost Predictions vs Actual")
plt.xlabel("Actual Values")
plt.legend()
plt.tight_layout()
plt.show()