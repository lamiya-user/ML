# -*- coding: utf-8 -*-
"""Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZmuW1VXQH9Yp5RFtplJrD-j4T3UwXrYR
"""

!pip install numpy==2.2.0
!pip install pandas==2.2.3
!pip install scikit-learn==1.6.0
!pip install matplotlib==3.9.3
!pip install seaborn==0.13.2

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.multiclass import OneVsOneClassifier
from sklearn.metrics import accuracy_score

import warnings
warnings.filterwarnings('ignore')

!pip install --force-reinstall numpy

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.multiclass import OneVsOneClassifier
from sklearn.metrics import accuracy_score

import warnings
warnings.filterwarnings('ignore')

!pip uninstall -y numpy scikit-learn

!pip install numpy==1.24.4 scikit-learn==1.3.2

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.multiclass import OneVsOneClassifier
from sklearn.metrics import accuracy_score

import warnings
warnings.filterwarnings('ignore')

url ="https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/GkDzb7bWrtvGXdPOfk6CIg/Obesity-level-prediction-dataset.csv"
data = pd.read_csv(url)
data.head()

"""to understand the distribution of the target variable.

"""

sns.countplot(y='NObeyesdad',data=data)
plt.title('Distribution of obesity levels')
plt.show()

print(data.isnull())

print(data.describe())

"""Pre Processing Data"""

continuous_columns = data.select_dtypes(include=['float64']).columns.tolist()

scaler = StandardScaler()
scaled_features = scaler.fit_transform(data[continuous_columns])

scaled_df = pd.DataFrame(scaled_features, columns=scaler.get_feature_names_out(continuous_columns))

scaled_data = pd.concat([data.drop(columns=continuous_columns), scaled_df], axis=1)

"""one hot encoding"""

from sklearn.preprocessing import OneHotEncoder

# Get categorical columns
categorical_columns = scaled_data.select_dtypes(include=['object']).columns.tolist()

# Remove target column
if 'NObeyesdad' in categorical_columns:
    categorical_columns.remove('NObeyesdad')

# Encode categorical features
encoder = OneHotEncoder(sparse_output=False, drop='first')
encoded_features = encoder.fit_transform(scaled_data[categorical_columns])

# Create DataFrame for encoded features
encoded_df = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out(categorical_columns))

# Combine with rest of the data
prepped_data = pd.concat([scaled_data.drop(columns=categorical_columns), encoded_df], axis=1)

"""encode the target variables"""

x =prepped_data['NObeyesdad'] = prepped_data['NObeyesdad'].astype('category').cat.codes
y =prepped_data.head()

"""Model Training and evaluation"""

print("Type of x:", type(x))
print("Type of y:", type(y))
print("Shape of x:", getattr(x, 'shape', 'No shape'))
print("Shape of y:", getattr(y, 'shape', 'No shape'))

print("Length of x:", len(x))
print("Length of y:", len(y))

print("First few entries in y:")
print(y.head() if hasattr(y, 'head') else y[:5])

x = data.drop(columns=['label'])
y = data['label']  # <- Must be 1D with 2111 values

x = data.drop(columns=['NObeyesdad'])  # drop label column
y = data['NObeyesdad']                 # this is your target

from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(
    x, y, test_size=0.2, random_state=42, stratify=y
)

"""Logistic regression with one versus all"""

# Re-do your x and y correctly with encoded features
x = data.drop(columns=['NObeyesdad'])        # features
y = data['NObeyesdad']                       # target

# Convert categorical features (e.g., 'Gender', 'MTRANS', etc.)
x_encoded = pd.get_dummies(x, drop_first=True)

# Then split
from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(
    x_encoded, y, test_size=0.2, random_state=42, stratify=y
)

# Now train the model
from sklearn.linear_model import LogisticRegression

model_ova = LogisticRegression(multi_class='ovr', max_iter=1000)
model_ova.fit(x_train, y_train)

"""evaluate the accuracy"""

y_pred_ova = model_ova.predict(x_test)
print("oVa")
print(f"Accuracy: {np.round(100*accuracy_score(y_test, y_pred_ova),2)}%")

"""One versus one"""

model_ovo = OneVsOneClassifier(LogisticRegression(max_iter=1000))
model_ovo.fit(x_train,y_train)

"""evaluate the accuracy"""

y_pred_ovo =model_ovo.predict(x_test)
print("OvO")
print(f"Accuracy:{np.round(100*accuracy_score(y_test,y_pred_ovo),2)}%")

x_rain,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state = 42, stratify =y)

# Re-do your x and y correctly with encoded features
x = data.drop(columns=['NObeyesdad'])        # features
y = data['NObeyesdad']                       # target

# Convert categorical features (e.g., 'Gender', 'MTRANS', etc.)
x_encoded = pd.get_dummies(x, drop_first=True)

# Then split
from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(
    x_encoded, y, test_size=0.1, random_state=42, stratify=y
)

# Now train the model
from sklearn.linear_model import LogisticRegression

model_ova = LogisticRegression(multi_class='ovr', max_iter=1000)
model_ova.fit(x_train, y_train)

y_pred_ova = model_ova.predict(x_test)
print("oVa")
print(f"Accuracy: {np.round(100*accuracy_score(y_test, y_pred_ova),2)}%")

"""creating a bar chart"""

feature_importance = np.mean(np.abs(model_ova.coef_),axis=0)
plt.barh(x.columns,feature_importance)
plt.title("Feature Importance")
plt.xlabel("Importance")
plt.show()
coefs = np.array([est.coef_[0] for est in model_ovo.estimators_])

# Now take the mean across all those classifiers
feature_importance = np.mean(np.abs(coefs), axis=0)

# Plot feature importance
plt.barh(X.columns, feature_importance)
plt.title("Feature Importance (One-vs-One)")
plt.xlabel("Importance")
plt.show()

def obesity_risk_pipeline(url, test_size=0.2):
    # Load data
    data = pd.read_csv(url)

    # Standardizing continuous numerical features
    continuous_columns = data.select_dtypes(include=['float64']).columns.tolist()
    scaler = StandardScaler()
    scaled_features = scaler.fit_transform(data[continuous_columns])

    # Converting to a DataFrame
    scaled_df = pd.DataFrame(scaled_features, columns=scaler.get_feature_names_out(continuous_columns))

    # Combining with the original dataset
    scaled_data = pd.concat([data.drop(columns=continuous_columns), scaled_df], axis=1)

    # Identifying categorical columns
    categorical_columns = scaled_data.select_dtypes(include=['object']).columns.tolist()
    categorical_columns.remove('NObeyesdad')  # Exclude target column

    # Applying one-hot encoding
    encoder = OneHotEncoder(sparse_output=False, drop='first')
    encoded_features = encoder.fit_transform(scaled_data[categorical_columns])

    # Converting to a DataFrame
    encoded_df = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out(categorical_columns))

    # Combining with the original dataset
    prepped_data = pd.concat([scaled_data.drop(columns=categorical_columns), encoded_df], axis=1)

    # Encoding the target variable
    prepped_data['NObeyesdad'] = prepped_data['NObeyesdad'].astype('category').cat.codes

    # Preparing final dataset
    X = prepped_data.drop('NObeyesdad', axis=1)
    y = prepped_data['NObeyesdad']

    # Splitting data
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42, stratify=y)

    # Training and evaluation
    model = LogisticRegression(multi_class='multinomial', max_iter=1000)
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    print("Accuracy:", accuracy_score(y_test, y_pred))

# Call the pipeline function with file_path
obesity_risk_pipeline(url, test_size=0.2)